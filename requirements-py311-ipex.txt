# Requirements for Python 3.11 with Intel Extension for PyTorch
# This setup provides optimized CPU inference with IPEX

# Core PyTorch with CUDA support
--index-url https://download.pytorch.org/whl/cu121
torch==2.5.1
torchvision
torchaudio

# Intel Extension for PyTorch (2-4x CPU speedup)
intel-extension-for-pytorch==2.5.0

# Transformers - latest from source for Qwen3 support
git+https://github.com/huggingface/transformers.git

# Model loading and quantization
accelerate>=0.26.0
auto-round>=0.7.0
safetensors>=0.4.0
sentencepiece>=0.1.99
protobuf>=3.20.0

# Utilities
psutil>=5.9.0
huggingface-hub>=0.19.0
tqdm>=4.65.0
numpy<2.0.0
scipy>=1.10.0

# Optional: Intel Neural Compressor for additional optimizations
# Uncomment to install:
# neural-compressor>=2.5.0

# Optional: OpenVINO for alternative inference backend
# Uncomment to install:
# openvino>=2024.0.0
# optimum-intel>=1.15.0

# Optional: ONNX Runtime with Intel optimizations
# Uncomment to install:
# onnxruntime-openvino>=1.17.0